{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrkech/GENERATIVE-METHODS-IN-GENOMICS-v2/blob/main/Copy_of_PHRED_TRANSFORMER_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h01blEsAF3jw"
      },
      "source": [
        "### Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "jc4vWOvgGF-T"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from transformers import T5Tokenizer, TFT5ForConditionalGeneration\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQWu76uMkRcl"
      },
      "source": [
        "### GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "idY4ueitn_lT",
        "outputId": "c34096a1-bc40-41a3-98d4-d97a6ff5c802"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "DEVICE_NAME = tf.test.gpu_device_name()\n",
        "if DEVICE_NAME != '/device:GPU:0':\n",
        "    print('GPU device not found. Training on CPU.')\n",
        "else:\n",
        "    print('Found GPU at: {}'.format(DEVICE_NAME))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P90wkR1TkUyB"
      },
      "source": [
        "### Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXfyGpMAGEg1",
        "outputId": "d3a69163-68a7-46a5-df86-5bc3d6c4d1da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PJg4jHWY2rJ"
      },
      "source": [
        "### Load Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "74be9jY8H1Yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5284edee-a304-4778-b370-9fc6db2196d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From <ipython-input-32-44d83ce35647>:4: load (from tensorflow.python.data.experimental.ops.io) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.load(...)` instead.\n"
          ]
        }
      ],
      "source": [
        "data_path = \"/content/drive/MyDrive/BIOINFORMATICS/THESIS_KECHAGIAS/DATA/DATASET/phred300_tf_dataset\"\n",
        "\n",
        "element_spec = tf.TensorSpec(shape=(300, 1), dtype=tf.float32)\n",
        "tf_dataset = tf.data.experimental.load(data_path, element_spec=element_spec)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tf_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "Thn68oYQ3RQQ",
        "outputId": "29b08151-b495-4cc4-d4a1-f3402fa7bd50"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.load_op._LoadDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.load_op._LoadDataset</b><br/>def __init__(path: str, element_spec: Any, compression: str, reader_func: Callable[[dataset_ops.Dataset], dataset_ops.Dataset])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/load_op.py</a>A dataset that loads previously saved dataset.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 177);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLj9RnEW96nP",
        "outputId": "a491c87b-a552-499a-f9c7-df5af332aa83",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.3655914 ]\n",
            " [0.3655914 ]\n",
            " [0.3655914 ]\n",
            " [0.3655914 ]\n",
            " [0.3655914 ]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.37634408]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.38709676]\n",
            " [0.11827957]\n",
            " [0.3655914 ]\n",
            " [0.38709676]\n",
            " [0.3655914 ]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.33333334]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.33333334]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.33333334]\n",
            " [0.39784947]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.29032257]\n",
            " [0.38709676]\n",
            " [0.33333334]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3548387 ]\n",
            " [0.38709676]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.38709676]\n",
            " [0.32258064]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.38709676]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.37634408]\n",
            " [0.37634408]\n",
            " [0.40860215]\n",
            " [0.2580645 ]\n",
            " [0.39784947]\n",
            " [0.32258064]\n",
            " [0.3548387 ]\n",
            " [0.38709676]\n",
            " [0.26881722]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.30107528]\n",
            " [0.38709676]\n",
            " [0.38709676]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.34408602]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.38709676]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.3655914 ]\n",
            " [0.38709676]\n",
            " [0.24731183]\n",
            " [0.38709676]\n",
            " [0.33333334]\n",
            " [0.38709676]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.3655914 ]\n",
            " [0.2580645 ]\n",
            " [0.32258064]\n",
            " [0.39784947]\n",
            " [0.32258064]\n",
            " [0.31182796]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.34408602]\n",
            " [0.38709676]\n",
            " [0.39784947]\n",
            " [0.34408602]\n",
            " [0.33333334]\n",
            " [0.31182796]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.38709676]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.40860215]\n",
            " [0.24731183]\n",
            " [0.38709676]\n",
            " [0.30107528]\n",
            " [0.39784947]\n",
            " [0.34408602]\n",
            " [0.30107528]\n",
            " [0.30107528]\n",
            " [0.30107528]\n",
            " [0.37634408]\n",
            " [0.40860215]\n",
            " [0.3655914 ]\n",
            " [0.39784947]\n",
            " [0.3655914 ]\n",
            " [0.24731183]\n",
            " [0.37634408]\n",
            " [0.30107528]\n",
            " [0.10752688]\n",
            " [0.30107528]\n",
            " [0.24731183]\n",
            " [0.16129032]\n",
            " [0.34408602]\n",
            " [0.37634408]\n",
            " [0.37634408]\n",
            " [0.30107528]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.33333334]\n",
            " [0.32258064]\n",
            " [0.37634408]\n",
            " [0.37634408]\n",
            " [0.40860215]\n",
            " [0.39784947]\n",
            " [0.22580644]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.2795699 ]\n",
            " [0.2795699 ]\n",
            " [0.2580645 ]\n",
            " [0.2580645 ]\n",
            " [0.37634408]\n",
            " [0.37634408]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.3548387 ]\n",
            " [0.34408602]\n",
            " [0.37634408]\n",
            " [0.17204301]\n",
            " [0.37634408]\n",
            " [0.2795699 ]\n",
            " [0.2795699 ]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.39784947]\n",
            " [0.22580644]\n",
            " [0.09677419]\n",
            " [0.02150538]\n",
            " [0.19354838]\n",
            " [0.21505377]\n",
            " [0.08602151]\n",
            " [0.24731183]\n",
            " [0.33333334]\n",
            " [0.2580645 ]\n",
            " [0.39784947]\n",
            " [0.37634408]\n",
            " [0.39784947]\n",
            " [0.34408602]\n",
            " [0.3548387 ]\n",
            " [0.3548387 ]\n",
            " [0.33333334]\n",
            " [0.08602151]\n",
            " [0.26881722]\n",
            " [0.24731183]\n",
            " [0.30107528]\n",
            " [0.39784947]\n",
            " [0.2795699 ]\n",
            " [0.34408602]\n",
            " [0.3655914 ]\n",
            " [0.09677419]\n",
            " [0.16129032]\n",
            " [0.10752688]\n",
            " [0.2795699 ]\n",
            " [0.38709676]\n",
            " [0.38709676]\n",
            " [0.31182796]\n",
            " [0.09677419]\n",
            " [0.23655914]\n",
            " [0.29032257]\n",
            " [0.30107528]\n",
            " [0.22580644]\n",
            " [0.08602151]\n",
            " [0.2580645 ]\n",
            " [0.3548387 ]\n",
            " [0.38709676]\n",
            " [0.38709676]\n",
            " [0.20430107]\n",
            " [0.3548387 ]\n",
            " [0.23655914]\n",
            " [0.11827957]\n",
            " [0.32258064]\n",
            " [0.16129032]\n",
            " [0.29032257]], shape=(300, 1), dtype=float32)\n",
            "2402568\n"
          ]
        }
      ],
      "source": [
        "iterator = iter(tf_dataset)\n",
        "first_element = next(iterator)\n",
        "print(first_element)\n",
        "\n",
        "print(len(tf_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "id": "mFqF0e0S9AXX"
      },
      "outputs": [],
      "source": [
        "def plot_quality_distributions(tf_dataset):\n",
        "    for batch, qualities_batch in enumerate(tf_dataset):\n",
        "        for i in range(qualities_batch.shape[0]):\n",
        "            plt.hist(qualities_batch[i,:,0], bins=20)\n",
        "            plt.title(f\"Quality Score Distribution for Sequence {i} in Batch {batch}\")\n",
        "            plt.xlabel(\"Quality Score\")\n",
        "            plt.ylabel(\"Frequency\")\n",
        "            plt.show()\n",
        "\n",
        "#plot_quality_distributions(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters"
      ],
      "metadata": {
        "id": "JkNpckPUzz_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model hyperparameters\n",
        "num_layers = 4  # Number of encoder layers\n",
        "d_model = 128  # Dimensionality of the model  <-- Define d_model here\n",
        "num_heads = 8  # Number of attention heads\n",
        "dff = 512  # Dimensionality of the feed-forward network\n",
        "input_vocab_size = 1000  # Size of the vocabulary (adjust if needed)\n",
        "maximum_position_encoding = 10000  # Maximum sequence length (adjust as needed)\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "BgsCEajtzzLJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "BUild the model."
      ],
      "metadata": {
        "id": "Ui1iqmeAN2xs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    '''\n",
        "    Positional Encoding\n",
        "\n",
        "    Args:\n",
        "        position: The max position in the sequence\n",
        "        d_model: The dimensionality of a model\n",
        "\n",
        "    Returns:\n",
        "        The positional encoding vector\n",
        "    '''\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1/ np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
        "    return pos * angle_rates"
      ],
      "metadata": {
        "id": "bOEpfWy-Sc3O"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads, trainable=True)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2  =tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(outl1)\n",
        "        ffn_output = seld.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n",
        "\n",
        "'''\n",
        "Code heavily based on:\n",
        "https://www.analyticsvidhya.com/blog/2021/01/implementation-of-attention-mechanism-for-caption-generation-on-transformers-using-tensorflow/\n",
        "https://ithelp.ithome.com.tw/articles/10271277?sc=iThomeR\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oGDBKv7im0OF",
        "outputId": "cacad8d0-a267-4a7e-aabd-9aabb92d5478"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCode heavily based on:\\nhttps://www.analyticsvidhya.com/blog/2021/01/implementation-of-attention-mechanism-for-caption-generation-on-transformers-using-tensorflow/\\nhttps://ithelp.ithome.com.tw/articles/10271277?sc=iThomeR\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __inti__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "\n",
        "        output = self.dense(concat_attention)\n",
        "\n",
        "        return output, attention_weights"
      ],
      "metadata": {
        "id": "J4JVPPgGqH7U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "\n",
        "    Args:\n",
        "      q: query shape == (..., seq_len_q, depth)\n",
        "      k: key shape == (..., seq_len_k, depth)\n",
        "      v: value shape == (..., seq_len_v, depth_v)\n",
        "      mask: Float tensor with shape broadcastable\n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "      output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "fXyyzhbyswC6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "yOm7lykPtOu_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                 maximum_position_encoding, rate=0.1):\n",
        "        super(TransformerEncoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "v0x4vmxet0fo"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # Cast step to float32\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "Ho_w5zxRxDFm"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "metadata": {
        "id": "o6pc3dtvzYvF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "7z7IfVC3zTsb"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "KZTKA6Nzzcby"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the number of samples to take for training\n",
        "train_size = int(len(tf_dataset) * 0.8)\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = tf_dataset.take(train_size)\n",
        "val_dataset = tf_dataset.skip(train_size)\n",
        "\n",
        "# Batch the datasets\n",
        "training_dataset = train_dataset.batch(BATCH_SIZE)\n",
        "validation_dataset = val_dataset.batch(BATCH_SIZE)\n",
        "\n",
        "# Example: Print the first batch from the training dataset\n",
        "for (batch, inp) in enumerate(training_dataset):\n",
        "    print(f\"Batch {batch}: {inp}\")\n",
        "    break  # Print only the first batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "keenH9K83HFa",
        "outputId": "0cdf4498-ac1b-47da-d9a1-737e8db6fcab"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch 0: [[[0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  ...\n",
            "  [0.32258064]\n",
            "  [0.16129032]\n",
            "  [0.29032257]]\n",
            "\n",
            " [[0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  ...\n",
            "  [0.11827957]\n",
            "  [0.17204301]\n",
            "  [0.23655914]]\n",
            "\n",
            " [[0.34408602]\n",
            "  [0.12903225]\n",
            "  [0.12903225]\n",
            "  ...\n",
            "  [0.19354838]\n",
            "  [0.07526882]\n",
            "  [0.07526882]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  [0.29032257]\n",
            "  ...\n",
            "  [0.09677419]\n",
            "  [0.07526882]\n",
            "  [0.11827957]]\n",
            "\n",
            " [[0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  [0.3655914 ]\n",
            "  ...\n",
            "  [0.40860215]\n",
            "  [0.17204301]\n",
            "  [0.19354838]]\n",
            "\n",
            " [[0.3548387 ]\n",
            "  [0.3655914 ]\n",
            "  [0.3548387 ]\n",
            "  ...\n",
            "  [0.29032257]\n",
            "  [0.2795699 ]\n",
            "  [0.23655914]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_transformer(transformer, train_dataset, val_dataset, num_epochs, log_dir):\n",
        "    \"\"\"Trains the Transformer model.\"\"\"\n",
        "\n",
        "    # Define metrics\n",
        "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(\n",
        "        name='train_accuracy')\n",
        "\n",
        "    # Create checkpoint object and manager\n",
        "    checkpoint = tf.train.Checkpoint(transformer=transformer,\n",
        "                                    optimizer=optimizer)\n",
        "    checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=3)\n",
        "\n",
        "    # Create TensorBoard callback\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        start = time.time()\n",
        "\n",
        "        train_loss.reset_states()\n",
        "        train_accuracy.reset_states()\n",
        "\n",
        "        # Iterate over the training dataset\n",
        "        for (batch, inp) in enumerate(train_dataset):\n",
        "            # Prepare target sequence (shifted by one position)\n",
        "            tar = inp[:, 1:]\n",
        "            inp = inp[:, :-1]\n",
        "\n",
        "            train_step(inp, tar)  # Call the train_step function\n",
        "\n",
        "            if batch % 50 == 0:\n",
        "                print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "\n",
        "        # Optional: Evaluate on validation set and log metrics to TensorBoard\n",
        "        # ...\n",
        "\n",
        "        print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "        print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "metadata": {
        "id": "ps6RuyFj7S-p"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_masks(inp, tar):\n",
        "    \"\"\"Creates all masks for training.\"\"\"\n",
        "\n",
        "    # Encoder padding mask (Used in the 1st attention block in the encoder)\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 2nd attention block in the decoder.\n",
        "    # This padding mask is used to mask the encoder outputs.\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    # Used in the 1st attention block in the decoder.\n",
        "    # It is used to pad and mask future tokens in the input received by\n",
        "    # the decoder.\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "\n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n",
        "\n",
        "def create_padding_mask(seq):\n",
        "    \"\"\"Creates a padding mask for a sequence.\"\"\"\n",
        "\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "\n",
        "    # add extra dimensions to add the padding\n",
        "    # to the attention logits.\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def create_look_ahead_mask(size):\n",
        "    \"\"\"Creates a look-ahead mask for a sequence.\"\"\"\n",
        "\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask  # (seq_len, seq_len)"
      ],
      "metadata": {
        "id": "rzDyWRd57oCU"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transformer = TransformerEncoder(num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=dropout_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "8ld--zVs75Dc",
        "outputId": "dd6cac01-6407-4990-f159-cdd47bb4e7fa"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Layer.__init__() got multiple values for argument 'trainable'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-49-77f1221cc0f2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransformerEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_vocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaximum_position_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-7ce7029d8021>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaximum_position_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-7ce7029d8021>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositional_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaximum_position_encoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menc_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mEncoderLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-742e361250c2>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, d_model, num_heads, dff, rate)\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEncoderLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiHeadAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoint_wise_feed_forward_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Layer.__init__() got multiple values for argument 'trainable'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "P90wkR1TkUyB",
        "NNf5ofzfFk_o",
        "zkl2DoIjFqdD"
      ],
      "authorship_tag": "ABX9TyMvHMoeR5lglpLYHPxTVTTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}